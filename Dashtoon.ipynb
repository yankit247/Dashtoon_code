{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPE7ueIBma0+iCcEnx3O3h4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yankit247/Dashtoon_code/blob/main/Dashtoon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbpbXhsIqnpm",
        "outputId": "41fd161f-c120-49fb-faa0-bad3792cde17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications import vgg19\n",
        "from keras.models import Model\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import tensorflow as tf\n",
        "\n",
        "# Update paths for Google Drive\n",
        "StylePath = '/content/drive/MyDrive/styled_images/'\n",
        "ContentPath = '/content/drive/MyDrive/content_images/'"
      ],
      "metadata": {
        "id": "lIbW8PyIqogn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable eager execution\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "# Function to run style transfer\n",
        "def Run_StyleTransfer(base_image_path, style_image_path, save_path):\n",
        "    # Placeholder values, replace with your actual values\n",
        "    img_nrows = 400\n",
        "    img_ncols = 400\n",
        "\n",
        "    base_image = preprocess_image(base_image_path, img_nrows, img_ncols)\n",
        "    style_reference_image = preprocess_image(style_image_path, img_nrows, img_ncols)\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n",
        "    else:\n",
        "        combination_image = K.placeholder((1, img_nrows, img_ncols, 3))\n",
        "\n",
        "    input_tensor = K.concatenate([base_image, style_reference_image, combination_image], axis=0)\n",
        "\n",
        "    # Load VGG19 model\n",
        "    vgg19_weights = '/content/drive/MyDrive/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "    model = vgg19.VGG19(input_tensor=input_tensor, include_top=False, weights=vgg19_weights)\n",
        "    outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "\n",
        "    content_weight = 0.025\n",
        "    style_weight = 1.0\n",
        "\n",
        "    # Extract features from the model\n",
        "    content_layer = 'block5_conv2'\n",
        "    style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "\n",
        "    base_image_features = outputs_dict[content_layer][0, :, :, :]\n",
        "    combination_features = outputs_dict[content_layer][2, :, :, :]\n",
        "\n",
        "    # Calculate content loss\n",
        "    content_score = get_content_loss(base_image_features, combination_features)\n",
        "\n",
        "   # Function to calculate style loss\n",
        "def get_style_loss(style, combination, img_nrows, img_ncols):\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))\n",
        "\n",
        "# Function to run style transfer\n",
        "def Run_StyleTransfer(base_image_path, style_image_path, save_path):\n",
        "    # Placeholder values, replace with your actual values\n",
        "    img_nrows = 400\n",
        "    img_ncols = 400\n",
        "\n",
        "    base_image = preprocess_image(base_image_path, img_nrows, img_ncols)\n",
        "    style_reference_image = preprocess_image(style_image_path, img_nrows, img_ncols)\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n",
        "    else:\n",
        "        combination_image = K.placeholder((1, img_nrows, img_ncols, 3))\n",
        "\n",
        "    input_tensor = K.concatenate([base_image, style_reference_image, combination_image], axis=0)\n",
        "\n",
        "    # Load VGG19 model\n",
        "    vgg19_weights = '/content/drive/MyDrive/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "    model = vgg19.VGG19(input_tensor=input_tensor, include_top=False, weights=vgg19_weights)\n",
        "    outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "\n",
        "    content_weight = 0.025\n",
        "    style_weight = 1.0\n",
        "\n",
        "    # Extract features from the model\n",
        "    content_layer = 'block5_conv2'\n",
        "    style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "\n",
        "    base_image_features = outputs_dict[content_layer][0, :, :, :]\n",
        "    combination_features = outputs_dict[content_layer][2, :, :, :]\n",
        "\n",
        "    # Calculate content loss\n",
        "    content_score = get_content_loss(base_image_features, combination_features)\n",
        "\n",
        "    # Calculate style loss\n",
        "    style_score = 0\n",
        "    for layer_name in style_layers:\n",
        "        style_reference_features = outputs_dict[layer_name][1, :, :, :]\n",
        "        combination_features = outputs_dict[layer_name][2, :, :, :]\n",
        "        style_score += get_style_loss(style_reference_features, combination_features, img_nrows, img_ncols)\n",
        "\n",
        "    # Combine content and style scores to get the total loss\n",
        "    loss = content_weight * content_score + style_weight * style_score\n",
        "\n",
        "    # Get the gradients of the generated image wrt the loss\n",
        "    grads = K.gradients(loss, combination_image)\n",
        "\n",
        "    # Combine loss and gradients\n",
        "    outputs = [loss]\n",
        "    if isinstance(grads, (list, tuple)):\n",
        "        outputs += grads\n",
        "    else:\n",
        "        outputs.append(grads)\n",
        "\n",
        "    # Create a function to calculate loss and gradients\n",
        "    f_outputs = K.function([combination_image], outputs)\n",
        "\n",
        "    # Define an evaluator class\n",
        "    class Evaluator(object):\n",
        "        def __init__(self):\n",
        "            self.loss_value = None\n",
        "            self.grads_values = None\n",
        "\n",
        "        def loss(self, x):\n",
        "            assert self.loss_value is None\n",
        "            x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "            outs = f_outputs([x])\n",
        "            loss_value = outs[0]\n",
        "            grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "            self.loss_value = loss_value\n",
        "            self.grad_values = grad_values\n",
        "            return self.loss_value\n",
        "\n",
        "        def grads(self, x):\n",
        "            assert self.loss_value is not None\n",
        "            grad_values = np.copy(self.grad_values)\n",
        "            self.loss_value = None\n",
        "            self.grad_values = None\n",
        "            return grad_values\n",
        "\n",
        "    # Initialize evaluator\n",
        "    evaluator = Evaluator()\n",
        "\n",
        "    # Run L-BFGS optimization\n",
        "    iterations = 200\n",
        "    best_loss, best_img = float('inf'), None\n",
        "\n",
        "    # Initialize x_opt\n",
        "    x_opt = preprocess_image(base_image_path, img_nrows, img_ncols)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        x_opt, min_val, info = fmin_l_bfgs_b(evaluator.loss,\n",
        "                                             x_opt.flatten(),\n",
        "                                             fprime=evaluator.grads,\n",
        "                                             maxfun=20,\n",
        "                                             disp=True,\n",
        "                                            )\n",
        "        if min_val < best_loss:\n",
        "            best_loss = min_val\n",
        "            best_img = x_opt.copy()\n",
        "\n",
        "    # Save the final image to Google Drive\n",
        "    save_path = '/content/drive/MyDrive/' + save_path\n",
        "    imgx = deprocess_image(best_img.copy())\n",
        "    save_img(save_path, imgx)\n",
        "\n",
        "    return imgx, save_path\n",
        "\n",
        "    # Save the final image to Google Drive\n",
        "    save_path = '/content/drive/MyDrive/' + save_path\n",
        "    imgx = deprocess_image(best_img.copy())\n",
        "    save_img(save_path, imgx)\n",
        "\n",
        "    return imgx, save_path\n",
        "\n",
        "# Example usage for the first set of images\n",
        "base_image_path_1 = '/content/drive/MyDrive/content_images/Andrei_Rublev_14.jpg'\n",
        "style_image_path_1 = '/content/drive/MyDrive/styled_images/0.jpg'\n",
        "imgg, save_path_1 = Run_StyleTransfer(base_image_path_1, style_image_path_1, 'final_image_1.jpg')\n",
        "\n",
        "# Display the final image\n",
        "plt.title(\"Final Image\", fontsize=20)\n",
        "plt.imshow(imgg)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u4UKmtxoqufd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uA9y0yh4vUjv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}